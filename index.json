[{"content":"Required IAM Permission: modify-instance-attribute\nRecommended but not required: start-instances, describe-instances, stop-instances (makes things go faster, requires less enumeration. The instance must be stopped to alter the user data)\nIf an adversary has access to the modify-instance attribute permission they can leverage it to escalate to root/System on an EC2 instance.\nUsually, user data scripts are only run the first time the instance is started, however this can be changed using cloud-init to run every time the instance restarts.\nTo do this, first create a file in the following format.\nContent-Type: multipart/mixed; boundary=\u0026quot;//\u0026quot; MIME-Version: 1.0 --// Content-Type: text/cloud-config; charset=\u0026quot;us-ascii\u0026quot; MIME-Version: 1.0 Content-Transfer-Encoding: 7bit Content-Disposition: attachment; filename=\u0026quot;cloud-config.txt\u0026quot; #cloud-config cloud_final_modules: - [scripts-user, always] --// Content-Type: text/x-shellscript; charset=\u0026quot;us-ascii\u0026quot; MIME-Version: 1.0 Content-Transfer-Encoding: 7bit Content-Disposition: attachment; filename=\u0026quot;userdata.txt\u0026quot; #!/bin/bash **commands here** --// Modify the commands here section to do whatever action you want. Setting a reverse shell, adding an ssh key to the default user, etc. are all good options.\nOnce you\u0026rsquo;ve done that, convert the file to base64. Linux can do this with the following command.\nbase64 file.txt \u0026gt; file.b64.txt\nWindows can do this with the following command.\ncertutil -encode file.txt tmp.b64 \u0026amp;\u0026amp; findstr /v /c:- tmp.b64 \u0026gt; file.b64.txt\nNow that you\u0026rsquo;ve base64 encoded your payload, you will leverage the modify-instance-attribute API call to change the user data of the target instance. Note: the instance will need to be stopped to modify its user data. You\u0026rsquo;ll either have to stop it yourself, or wait for something else to stop it.\naws ec2 modify-instance-attribute \\ --instance-id=xxx \\ --attribute userData \\ --value file://file.b64.txt With that change made, simply start the instance again and your command will be executed with root/System.\n","description":"Escalate privileges on an EC2 instance by modifying the user-data scripts with modify-instance-attribute.","id":0,"section":"aws","tags":null,"title":"Local Privilege Escalation: User Data","uri":"https://hackingthe.cloud/aws/exploitation/local-priv-esc-mod-instance-att/"},{"content":"When using EC2 instances a common design pattern is to define a user data script to be run when an instance is first started or after a reboot. These scripts are typically used to install software, download a config, etc. Additionally these scripts are run as root or System which makes them even more useful. Should we gain access to an EC2 instance we may be able to persist by abusing user data scripts via two different methods.\nModify the User Data Script Required IAM Permission: modify-instance-attribute\nRecommended but not required: start-instances, describe-instances, stop-instances (makes things go faster, requires less enumeration. The instance must be stopped to alter the user data)\nIf we have permission to directly modify the user data scripts, we can potentially persist by adding our own backdoor to it. To do this, we must stop the instance because user data scripts can only be modified when the instance is stopped. You could theoretically wait for this to happen naturally, have a script that constantly tries to modify it, or stop it yourself if you have permissions to do so.\nThe steps to modify user data scripts can be found here.\nModify a Resource Called by the Script In situations where we cannot modify the user data script itself, we may be able to modify a resource called by the script. Say for example a script is downloaded by an S3 bucket, we may be able to add our backdoor to it.\n","description":"Maintain access to an EC2 instance and it's IAM role via user data scripts.","id":1,"section":"aws","tags":null,"title":"User Data Script Persistence","uri":"https://hackingthe.cloud/aws/post_exploitation/user_data_script_persistence/"},{"content":"A common pattern when using EC2 is to define a user data script to be run when an instance is first started or after a reboot. These scripts are typically used to install software, download and set a config, etc. Oftentimes the scripts and packages are pulled from S3 and this introduces an opportunity for a developer/ops person to make a mistake.\nIf the IAM role is too permissive and allows the role to write to that location, an adversary can leverage this for privilege escalation. Additionally, if there is any other kind of misconfiguration on the bucket itself, or another role which has access gets compromised, an adversary can take advantage of this as well.\nTake the following user data script:\n#!/bin/bash aws s3 cp s3://example-boot-bucket/start_script.sh /root/start_script.sh chmod +x /root/start_script.sh /root/start_script.sh On first launch, the EC2 instance will pull the start_script from S3 and will run it. If an adversary can write to that location, they can escalate privileges or gain control of the EC2 instance.\nIn addition to new instances being spun up or after a reboot, poisoning the scripts/applications can also effect EC2 instances in an Auto Scaling Group.\r ","description":"Escalate privileges on an EC2 instance by modifying scripts and packages called by user data.","id":2,"section":"aws","tags":null,"title":"Local Privilege Escalation: User Data 2","uri":"https://hackingthe.cloud/aws/exploitation/local-priv-esc-user-data-s3/"},{"content":"Original Research: Ian Williams\nLink to Tool: GitHub\nWhen performing an AWS assessment you will likely encounter IAM Credentials. Traditionally, the majority of these that you would find would only be usable from the AWS CLI. Using a tool called AWS Consoler you can create links that will allow you to access the AWS Console. In this example we will walk through gathering credentials and using those credentials along with Consoler to generate a Console link.\nFirst, we need to gather valid IAM credentials. These are typically found a number of different ways. In this example, we have shell access to an EC2 instance with an attached role and we will curl the metadata service to access them.\nNext, install and compile AWS Consoler (install Python dependencies with pip and then do a sudo make install).\nFrom here invoke the Consoler tool and provide the -a (access key) -s (secret access key) and -t (session token) flags along with the retrieved values.\nThis will generate a link you can use to access the AWS Console.\n","description":"Leverage stolen credentials to use the AWS Console.","id":3,"section":"aws","tags":null,"title":"AWS Consoler","uri":"https://hackingthe.cloud/aws/post_exploitation/aws_consoler/"},{"content":"Link to Tool: GitHub\nWhen attacking AWS you may compromise credentials for an IAM user or role. This can be an excellent step to gain access to other resources, however it presents a problem for us. How do we know what we have access to? Unless these credentials have specific IAM permissions we won\u0026rsquo;t be able to look them up, and we may not have enough context clues from where we found the credentials to know about them.\nThis leaves us with basically one option, brute force the permissions. To do this, we will try as many AWS API calls as possible to determine what we have access to. There are several tools to do this however here we will be covering enumerate-iam by Andr√©s Riancho.\nTo use enumerate-iam, simply pull a copy of the tool from GitHub, provide the credentials, and watch the magic happen. All calls by enumerate-iam are non-destructive, meaning only get and list operations are used. This reduces the risk of accidentally deleting something in a client\u0026rsquo;s account.\nuser@host:/enum$ ./enumerate-iam.py --access-key $AWS_ACCESS_KEY_ID --secret-key $AWS_SECRET_ACCESS_KEY --session-token $AWS_SESSION_TOKEN 2020-12-20 18:41:26,375 - 13 - [INFO] Starting permission enumeration for access-key-id \u0026quot;ASIAAAAAAAAAAAAAAAAA\u0026quot; 2020-12-20 18:41:26,812 - 13 - [INFO] -- Account ARN : arn:aws:sts::012345678912:assumed-role/role-b/user-b 2020-12-20 18:41:26,812 - 13 - [INFO] -- Account Id : 012345678912 2020-12-20 18:41:26,813 - 13 - [INFO] -- Account Path: assumed-role/role-b/user-b 2020-12-20 18:41:27,283 - 13 - [INFO] Attempting common-service describe / list brute force. 2020-12-20 18:41:34,992 - 13 - [INFO] -- codestar.list_projects() worked! 2020-12-20 18:41:35,928 - 13 - [INFO] -- sts.get_caller_identity() worked! 2020-12-20 18:41:36,838 - 13 - [INFO] -- dynamodb.describe_endpoints() worked! 2020-12-20 18:41:38,107 - 13 - [INFO] -- sagemaker.list_models() worked! Updating APIs With an attack surface that evolves as rapidly as AWS, we often have to find and abuse newer features. This is one area where enumerate-iam shines. The tool itself has a built in feature to read in new AWS API calls from the JavaScript SDK, and use that information to brute force. After downloading enumerate-iam, perform the following steps to update the API lists.\ncd enumerate_iam/ git clone https://github.com/aws/aws-sdk-js.git python generate_bruteforce_tests.py This will create or update a file named bruteforce_tests.py under enumerate-iam.\nOPSEC Considerations One thing to note is that this tool is very noisy and will generate a ton of CloudTrail logs. This makes it very easy for a defender to spot this activity and lock you out of that role or user. Try other methods of permission enumeration first, or be willing to lose access to these credentials before resorting to brute-force.\nAs of 12/20/2020 there is a bug in the AWS API that allows you to enumerate a variety of permissions without logging to CloudTrail. Try that method first, before resorting to brute force so you can stay more stealthy.\r ","description":"Brute force the IAM permissions of a user or role to see what you have access to.","id":4,"section":"aws","tags":null,"title":"Brute Force IAM Permissions","uri":"https://hackingthe.cloud/aws/enumeration/brute_force_iam_permissions/"},{"content":"A common occurrence while performing penetration testing on AWS is leveraging SSRF, XXE, command injection, etc. to steal IAM credentials from the meta data service. This can allow you to execute API calls you otherwise wouldn\u0026rsquo;t be able to (especially if you can\u0026rsquo;t get code execution on the EC2 instance), however it comes at a penalty. There is a GuardDuty rule which detects IAM credentials being used outside of EC2 called IAMUser/InstanceCredentialExfiltration.\nThe wording is very specific, \u0026ldquo;This finding informs you of attempts to run AWS API operations from a host outside of EC2\u0026rdquo;. It does not mean outside of EC2 instances in your account. It mean outside of EC2 AT ALL. As a result, you can use those credentials on ANY EC2 instance, including one you control. Doing so will not trigger the credential exfiltration GuardDuty finding.\n","description":"When stealing IAM credentials from an EC2 instance you can avoid a GuardDuty detection by using the keys from another EC2 instance.","id":5,"section":"aws","tags":null,"title":"Bypass Credential Exfiltration Detection","uri":"https://hackingthe.cloud/aws/avoiding-detection/steal-keys-undetected/"},{"content":"When making AWS API requests on common penetration testing OS\u0026rsquo;s GuardDuty will detect this and trigger a PenTest Finding.\nThis is caused by the user agent name that is passed in the API request. By modifying that we can prevent GuardDuty from detecting that we are operating from a \u0026ldquo;pentest\u0026rdquo; Linux distribution.\nIf your assessment requires you to remain undetected it\u0026rsquo;s probably easier to leverage a \u0026ldquo;safe\u0026rdquo; OS like Ubuntu, Mac OS, or Windows.\r To do this, identify the location of your session.py in the botocore package. For example, on a default Kali Linux install it can be found at /usr/local/lib/python3.7/dist-packages/botocore/session.py.\nOn line 456 (at the time of writing), you should see the following.\nplatform.system() and platform.release() are similar to uname -o and uname -r. On a stock Kali install it will generate the following values.\nTo get around this, modify the code and replace it with legitimate user agent strings like those found in Pacu. With this capability you can mask your user agent to look like anything you want. Even arbitrary values like below.\n","description":"Prevent Kali Linux, ParrotOS, and Pentoo Linux from throwing GuardDuty alerts by modifying the User Agent string.","id":6,"section":"aws","tags":null,"title":"Bypass GuardDuty Pentest Findings","uri":"https://hackingthe.cloud/aws/avoiding-detection/guardduty-pentest/"},{"content":"Security Groups in AWS have an interesting capability known as Connection Tracking. This allows the security groups to track information about the network traffic and allow/deny that traffic based on the Security Group rules.\nThere are two kinds of traffic flows; tracked and untracked. For example the AWS documentation mentions a tracked flow as the following, \u0026ldquo;if you initiate an ICMP ping command to your instance from your home computer, and your inbound security group rules allow ICMP traffic, information about the connection (including the port information) is tracked. Response traffic from the instance for the ping command is not tracked as a new request, but rather as an established connection and is allowed to flow out of the instance, even if your outbound security group rules restrict outbound ICMP traffic\u0026rdquo;.\nAn interesting side effect of this is that tracked connections are allowed to persist, even after a Security Group rule change.\nLet\u0026rsquo;s take a simple example: There is an EC2 instance that runs a web application. This EC2 instance has a simple Security Group that allows SSH, port 80, and port 443 inbound, and allows all traffic outbound. This EC2 instance is in a public subnet and is internet facing.\nWhile performing a penetration test you\u0026rsquo;ve gained command execution on this EC2 instance. In doing so, you pop a simple reverse shell. You work your magic on the box before eventually triggering an alert to our friendly neighborhood defender. They follow their runbooks which may borrow from the official AWS whitepaper on incident response.\nAs part of the \u0026ldquo;Isolate\u0026rdquo; step, the typical goal is to isolate the affected EC2 instance with either a restrictive Security Group or an explicit Deny NACL. The slight problem with this is that NACLs affect the entire subnet, and if you are operating in a space with a ton of EC2 instances the defender is unlikely to want to cause an outage for all of them. As a result, swapping the Security Group is the recommended procedure.\nThe defender switches the Security Group from the web and ssh one, to one that does not allow anything inbound or outbound.\nThe beauty of connection tracking is that because you\u0026rsquo;ve already established a connection with your shell, it will persist. So long as you ran the shell before the SG change, you can continue scouring the box and looking for other vulnerabilities.\nTo be clear, if the restrictive security group doesn\u0026rsquo;t allow for any outbound rules we won\u0026rsquo;t be able to communicate out (and if you\u0026rsquo;re using a beaconing C2 that will not function).\n","description":"Abuse security group connection tracking to maintain persistence even when security group rules are changed.","id":7,"section":"aws","tags":null,"title":"Connection Tracking","uri":"https://hackingthe.cloud/aws/general-knowledge/connection-tracking/"},{"content":"Original Research: Nick Frichette\nLink to Tool: aws_stealth_perm_enum\nAfter compromising an IAM credential while attacking AWS, your next task will be to determine what permissions that credential has scoped to them.\nAside from guessing, enumerating these permissions would typically require a tool to brute force them like enumerate-iam (which is a fantastic tool). The problem of course is that this will generate a ton of CloudTrail logs and will alert any defender. This poses a challenge to us, how can we enumerate permissions in a stealthy manner?\nThe good news is that there is a bug in the AWS API that affects 589 actions across 39 different AWS services. This bug is a result of a mishandling of the Content-Type header, and when that header is malformed in a specific way the results are not logged to CloudTrail. Based on the response codes/body we can determine if the role does or does not have permission to make that API call.\nThe following services are affected, although please note, that not all actions for these services can be enumerated.\n         application-autoscaling appstream   athena autoscaling-plans   aws-marketplace cloudhsm   codecommit codepipeline   codestar comprehend   cur datapipeline   dax discovery   forecast gamelift   health identitystore   kinesis kinesisanalytics   macie mediastore   mgh mturk-requester   opsworks-cm personalize   redshift-data route53domains   route53resolver sagemaker   secretsmanager shield   sms snowball   support tagging   textract translate   workmail     As of 12/19/2020, DirectConnect is no longer affected by this bug.\r For an in depth explanation for the bug, please see the original research. In this article we will just discuss how to take advantage of it.\r There are some conditions to the enumeration, and they are defined below.\n1 - The AWS service uses the JSON 1.1 protocol.\n2 - The API actions returns a unique error code depending on the permission set.\n3 - The resource associated with that action is set to \u0026ldquo;*\u0026rdquo;.\nTo perform the enumeration there is a script here. Setting the credentials as environment variables and then running the script will inform you what API permissions you have available to you.\n","description":"Leverage a bug in the AWS API to enumerate permissions for a role without logging to CloudTrail and alerting the Blue Team.","id":8,"section":"aws","tags":null,"title":"Enumerate Permissions without Logging to CloudTrail","uri":"https://hackingthe.cloud/aws/enumeration/stealth_perm_enum/"},{"content":"While performing an assessment in AWS it is not uncommon to come across access keys and not know what account they are associated with. If your scope is defined by the AWS account ID, this may pose a problem as you\u0026rsquo;d likely not want to use them if they are out of scope.\nTo solve this problem you can use sts:GetAccessKeyInfo to return the account ID of the credentials. This action will only be logged to the account calling the action (which should be your account, not the target\u0026rsquo;s).\nuser@host:~$ aws sts get-access-key-info --access-key-id=ASIA1234567890123456 { \u0026quot;Account\u0026quot;: \u0026quot;123456789012\u0026quot; } ","description":"During an assessment you may find AWS IAM credentials but not know what account they are associated with. Use this to get the account ID.","id":9,"section":"aws","tags":null,"title":"Get Account ID from AWS Access Keys","uri":"https://hackingthe.cloud/aws/enumeration/get-account-id-from-keys/"},{"content":"Last updated: 12/20/2020\nSource\n   Prefix Entity Type     ABIA AWS STS service bearer token   ACCA Context-specific credential   AGPA Group   AIDA IAM user   AIPA Amazon EC2 instance profile   AKIA Access key   ANPA Managed policy   ANVA Version in a managed policy   APKA Public key   AROA Role   ASCA Certificate   ASIA Temporary (AWS STS) keys    ","description":"Chart of the IAM ID Prefixes.","id":10,"section":"aws","tags":null,"title":"IAM ID Identifiers","uri":"https://hackingthe.cloud/aws/general-knowledge/iam-key-identifiers/"},{"content":"Original Research: Nick Frichette\nProof of Concept: GitHub\nThe SSM Agent is responsible for allowing EC2 instances to communicate with SSM services. The agent authenticates with SSM via the IAM role and the credentials in the Metadata Service. As a result, if you gain access to an EC2 instance or its IAM credentials you can spoof the agent and intercept EC2 Messages and SSM Sessions.\nFor an in depth explanation of how this works, please see the original research.\nThe tools used in this page are proof of concept, and should not be used for serious use cases. If you create or find a more production-ready tool please open an issue.\r Intercept EC2 Messages The normal operations of the SSM Agent is to poll for messages it has been sent. We can abuse this functionality by frequently polling ourselves. Doing so, will increase the likelihood (to a near guarantee) that we receive the messages before the real SSM agent does.\nBy abusing this functionality we can intercept the EC2 messages and response with our own output, allowing us to force a \u0026ldquo;Success\u0026rdquo; response.\nUsing the ssm-send-command-interception.py PoC:\nIntercept SSM Sessions Normally the SSM Agent will spawn a WebSocket connection back to SSM. This first WebSocket is the control channel and is responsible for spawning the data channels (which actually process the information). Due to this setup, we can spawn our own control channel and intercept all incoming connections. This can allow us to intercept or modify the communications happening, and potentially allow us to intercept sensitive commands and credentials.\nUsing the ssm-session-interception.py PoC:\n","description":"With access to an EC2 instance you can intercept, modify, and spoof SSM communications","id":11,"section":"aws","tags":null,"title":"Intercept SSM Communications","uri":"https://hackingthe.cloud/aws/post_exploitation/intercept_ssm_communications/"},{"content":"Every EC2 instance has access to something called the instance metadata service (IMDS). This contains (surprise) metadata about that specific EC2 instance.\nHow to Access the Metadata Service The metadata service can be accessed at http://169.254.169.254/latest/meta-data/ from the EC2 instance.\nIMDSv2 Version two of the metadata service has added protections against SSRF and requires the user to create and use a token. You can access it via the following.\nuser@host:~$ TOKEN=`curl -X PUT \u0026quot;http://169.254.169.254/latest/api/token\u0026quot; -H \u0026quot;X-aws-ec2-metadata-token-ttl-seconds: 21600\u0026quot;` \\ \u0026amp;\u0026amp; curl -H \u0026quot;X-aws-ec2-metadata-token: $TOKEN\u0026quot; -v http://169.254.169.254/latest/meta-data/ What does the Metadata Service Contain The following information was pulled from here.\n   Endpoint Description     ami-id The AMI ID used to launch the instance.   ami-launch-index If you started more than one instance at the same time, this value indicates the order in which the instance was launched. The value of the first instance launched is 0.   ami-manifest-path The path to the AMI manifest file in Amazon S3. If you used an Amazon EBS-backed AMI to launch the instance, the returned result is unknown.   hostname The private IPv4 DNS hostname of the instance. In cases where multiple network interfaces are present, this refers to the eth0 device (the device for which the device number is 0).   iam/info If there is an IAM role associated with the instance, contains information about the last time the instance profile was updated, including the instance\u0026rsquo;s LastUpdated date, InstanceProfileArn, and InstanceProfileId. Otherwise, not present.   iam/security-credentials/role-name If there is an IAM role associated with the instance, role-name is the name of the role, and role-name contains the temporary security credentials associated with the role. Otherwise, not present.   identity-credentials/ec2/info [Internal use only] Information about the credentials in identity-credentials/ec2/security-credentials/ec2-instance. These credentials are used by AWS features such as EC2 Instance Connect, and do not have any additional AWS API permissions or privileges beyond identifying the instance.   instance-id The ID of this instance.   local-hostname The private IPv4 DNS hostname of the instance. In cases where multiple network interfaces are present, this refers to the eth0 device (the device for which the device number is 0).   local-ipv4 The private IPv4 address of the instance. In cases where multiple network interfaces are present, this refers to the eth0 device (the device for which the device number is 0).   public-hostname The instance\u0026rsquo;s public DNS. This category is only returned if the enableDnsHostnames attribute is set to true.   public-ipv4 The public IPv4 address. If an Elastic IP address is associated with the instance, the value returned is the Elastic IP address.   public-keys/0/openssh-key Public key. Only available if supplied at instance launch time.   security-groups The names of the security groups applied to the instance.    ","description":"An Introduction to the Metadata Service and how we can use it.","id":12,"section":"aws","tags":null,"title":"Introduction to the Metadata Service","uri":"https://hackingthe.cloud/aws/general-knowledge/intro_metadata_service/"},{"content":"Instance user data is used to run commands when an EC2 instance is started or rebooted. This can be an excellent source of information for us as attackers. It typically takes the form of a shell script that can be accessed from the EC2 instance.\nHow to Access the User Data User data can be accessed at http://169.254.169.254/latest/user-data/ from the EC2 instance.\nIMDSv2 Version two of the user data service has added protections against SSRF and requires the user to create and use a token. You can access it via the following.\nuser@host:~$ TOKEN=`curl -X PUT \u0026quot;http://169.254.169.254/latest/api/token\u0026quot; -H \u0026quot;X-aws-ec2-metadata-token-ttl-seconds: 21600\u0026quot;` \\ \u0026amp;\u0026amp; curl -H \u0026quot;X-aws-ec2-metadata-token: $TOKEN\u0026quot; -v http://169.254.169.254/latest/user-data/ ","description":"An Introduction to User Data and how it is used.","id":13,"section":"aws","tags":null,"title":"Introduction to User Data","uri":"https://hackingthe.cloud/aws/general-knowledge/introduction_user_data/"},{"content":"Original Research: Daniel Heinsen\nLink to Tool: GitHub\nWhen doing an assessment in AWS you may want to maintain access for an extended period of time. You may not have the ability to create a new IAM user, or create a new key for existing users. How else can you extend your access? Role Chain Juggling.\nRole chaining is a recognized functionality of AWS in that you can use one assumed role to assume another one. When this happens the expiration field of the credentials is refreshed. This allows us to keep refreshing credentials over an over again.\nThrough this, you can extend your access by chaining assume-role calls.\nYou can chain the same role multiple times so long as the Trust Policy is configured correctly. Additionally, finding roles that can assume each other will allow you to cycle back and forth.\r To automate this work Daniel Heinsen developed a tool to keep the juggling going.\nuser@host:$ ./aws_role_juggler.py -h usage: aws_role_juggler.py [-h] [-r ROLE_LIST [ROLE_LIST ...]] optional arguments: -h, --help show this help message and exit -r ROLE_LIST [ROLE_LIST ...], --role-list ROLE_LIST [ROLE_LIST ...] ","description":"Keep your access by chaining assume-role calls.","id":14,"section":"aws","tags":null,"title":"Role Chain Juggling","uri":"https://hackingthe.cloud/aws/post_exploitation/role-chain-juggling/"},{"content":"One of the most commonly taught tactics in AWS exploitation is the use of Server Side Request Forgery (SSRF) to access the EC2 metadata service.\nAll EC2 Instances have access to the metadata service at 169.254.169.254. This contains useful information about the instance such as it\u0026rsquo;s IP address, the name of the security group, etc. On EC2 instances that have an IAM role attached the metadata service will also contain IAM credentials to authenticate as this role. Depending on what version of IMDS is in place, and what capabilities the SSRF has we can steal those credentials.\nIt is also worth noting that shell access to the EC2 instance would also allow an adversary to gather these credentials.\nThe attack as described here will not work with IMDSv2. For more information and options please refer to the documentation. IMDSv1 is still the default for EC2, so it is worth identifying what version is in place.\r In this example there is a web server running on port 80 of the EC2 instance. This web server has a simple SSRF vulnerability, allowing us to make GET requests to arbitrary addresses. We can leverage this to make a request to http://169.254.169.254.\nTo determine if the EC2 instance has an IAM role associated with it, look for http://169.254.169.254/latest/meta-data/iam/. A 404 response indicates there is no IAM role associated. You may also get a 200 response that is empty, this indicates that there was an IAM Role however it has since been revoked.\nIf there is a valid role you can steal, make a request to http://169.254.169.254/latest/meta-data/iam/security-credentials/. This will return the name of the IAM role the credentials represent. In the example below we see that the role name is \u0026lsquo;ec2-default-ssm\u0026rsquo;.\nTo steal the credentials, append the role name to your previous query. For example, with the name above we\u0026rsquo;d query http://169.254.169.254/latest/meta-data/iam/security-credentials/ec2-default-ssm/.\nThese credentials can then be used in the AWS CLI or other means to make API calls as the IAM role.\n","description":"Old faithful; How to steal IAM Role credentials via the EC2 Metadata service via SSRF.","id":15,"section":"aws","tags":null,"title":"Steal EC2 Metadata Credentials via SSRF","uri":"https://hackingthe.cloud/aws/exploitation/ec2-metadata-ssrf/"},{"content":"In Lambda, IAM credentials are passed into the function via environment variables. The benefit for the adversary is that these credentials can be leaked via file read vulnerabilities such as XML External Entity attacks or SSRF that allows the file protocol. This is because \u0026ldquo;everything is a file\u0026rdquo;.\nIAM credentials can be accessed via reading /proc/self/environ\nIn the event that /proc/self/environ is blocked by a WAF, check if you can read the environment variables of other processes. This can be done by reading /proc/#/environ where \u0026lsquo;#\u0026rsquo; is some number often between 1 and 20.\r In addition to IAM credentials, Lambda functions also have event data that is passed to the function when it is started. This data is made available to the function via the runtime interface. Unlike IAM credentials, this data is accessible over standard SSRF at http://localhost:9001/2018-06-01/runtime/invocation/next.\nThis will include information about what invoked the Lambda function and may be valuable depending on the context.\n","description":"Leverage file read and SSRF vulnerabilities to steam IAM credentials and event data from Lambda.","id":16,"section":"aws","tags":null,"title":"Steal IAM Credentials and Event Data from Lambda","uri":"https://hackingthe.cloud/aws/exploitation/lambda-steal-iam-credentials/"},{"content":"Original Research: Spencer Gietzen\nLink to Tool: GitHub\nLink to Pacu Module: GitHub\nWith just the account id of a target you can enumerate the names of IAM users and roles by abusing Resource-Based Policies.\nThere are a few ways to do this, for example, Pacu\u0026rsquo;s module will attempt to change the AssumeRole policy of a role in your account and specify a role in another account.\nAnother way would be to use S3 Bucket Policies. Take the following example:\n{ \u0026quot;Version\u0026quot;: \u0026quot;2012-10-17\u0026quot;, \u0026quot;Statement\u0026quot;: [ { \u0026quot;Sid\u0026quot;: \u0026quot;Example permissions\u0026quot;, \u0026quot;Effect\u0026quot;: \u0026quot;Deny\u0026quot;, \u0026quot;Principal\u0026quot;: { \u0026quot;AWS\u0026quot;: \u0026quot;arn:aws:iam::123456789123:role/role_name\u0026quot; }, \u0026quot;Action\u0026quot;: \u0026quot;s3:ListBucket\u0026quot;, \u0026quot;Resource\u0026quot;: \u0026quot;arn:aws:s3:::*bucket you own*\u0026quot; } ] } You would apply this policy to a bucket you own. By specifying a principal in the target account (123456789123), you can determine if that principals exists. If setting the bucket policy succeeds you know the role exists. If it fails you know the role does not.\nDoing either of these things will generate a lot of CloudTrail events, specifically UpdateAssumeRolePolicy or PutBucketPolicy in your account. If your intention is to be stealthy is is not advised (or required) to use a targets credentials. Instead you should use your own.\r While this works for both IAM users and roles, this will also work with service-linked roles. This will allow you to enumerate various services the account uses, such as GuardDuty or Organizations.\r To automate this process you can use the Pacu Module or this which will attempt to brute force it for you.\nusage: main.py [-h] --id ID --my_bucket MY_BUCKET [--wordlist WORDLIST] (--role | --user) Enumerate IAM/Users of an AWS account. You must provide your OWN AWS account and bucket optional arguments: -h, --help show this help message and exit --id ID The account id of the target account --my_bucket MY_BUCKET The bucket used for testing (belongs to you) --wordlist WORDLIST Wordlist containers user/role names --role Search for a IAM Role --user Search for a IAM User ","description":"Leverage cross account behaviors to enumerate IAM users and roles in a different AWS account without authentication.","id":17,"section":"aws","tags":null,"title":"Unauthenticated Enumeration of IAM Users and Roles","uri":"https://hackingthe.cloud/aws/enumeration/enum_iam_user_role/"},{"content":"After finding or stealing IAM credentials during an assessment you will need to identify what they are used for, or if they are valid. The most common method for doing so would be the get-caller-identity API call. This is beneficial for a few reasons, in particular that it requires no special permissions to call.\nUnfortunately (while unlikely) there is the possibility that this API call may be monitored for sensitive accounts. Additionally, if our goal is to be as stealthy as possible we may not want to use this. As a result we need alternatives. The good news for us is that a lot of AWS services will disclose the calling role along with the account ID as a result of an error. The following is certainly not a comprehensive list, and note that the principal needs to NOT have IAM permissions to make this call to return the information as an error.\nNot all API calls exhibit this behavior. Failed EC2 API calls, for example, will return a variant of the following.\nAn error occurred (UnauthorizedOperation) when calling the DescribeInstances operation: You are not authorized to perform this operation. sns publish sns:Publish will return the ARN of the calling user/role without logging to CloudTrail. To use this method, you must provide a valid AWS account id in the API call. This can be your own account id, or the account id of anyone else.\nuser@host:$ aws sns publish --topic-arn arn:aws:sns:us-east-1:*account id*:aaa --message aaa An error occurred (AuthorizationError) when calling the Publish operation: User: arn:aws:sts::123456789123:assumed-role/example_role/i-00000000000000000 is not authorized to perform: SNS:Publish on resource: arn:aws:sns:us-east-1:*account id*:aaa sdb list-domains As found by Spencer Gietzen, the API call for sdb list-domains will return verify similar information to get-caller-identity.\nuser@host:$ aws sdb list-domains --region us-east-1 An error occurred (AuthorizationFailure) when calling the ListDomains operation: User (arn:aws:sts::123456789012:assumed-role/example_role/i-00000000000000000) does not have permission to perform (sdb:ListDomains) on resource (arn:aws:sdb:us-east-1:123456789012:domain/). Contact account owner. As of August 15, 2020 these calls are now tracked in CloudTrail (tweet).\r route53 get-account-limit route53 get-account-limit will produce a similar result.\nlogs associate-kms-key logs associate-kms-key will produce a similar result.\n","description":"During an assessment you may find AWS IAM credentials. Use these tactics to identify the principal of the keys.","id":18,"section":"aws","tags":null,"title":"Whoami - Get Principal Name From Keys","uri":"https://hackingthe.cloud/aws/enumeration/whoami/"}]